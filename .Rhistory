x="Final rank",
y="Total team value",
caption="Source: https://fantasy.premierleague.com/a/leagues/standings/122838/classic")
leagueDetailed %>%
filter(event == 38) %>%
mutate(value=value/10, bank=bank/10, total = value+bank) %>%
ggplot(aes(x=overall_rank, y=total)) +
geom_point() +
geom_smooth(method = "lm", se=FALSE) +
scale_x_comma(limits = c(0, 3750000)) +
theme_ipsum(grid="XY", base_size = 14, axis_title_size = 14, caption_size = 12,
plot_title_size = 18, subtitle_size = 14) +
labs(title="Final Ranking vs. Team Value",
subtitle="Sample of users taken from my mini-leage",
x="Final rank",
y="Total team value",
caption="Source: https://fantasy.premierleague.com/a/leagues/standings/122838/classic")
league <- list()
for (i in 1:51) {
# get detailed data for users
data <- jsonlite::read_json(paste0("https://fantasy.premierleague.com/drf/leagues-classic-standings/268527?phase=1&lsPage=", i),
simplifyVector = TRUE)
# append dataframe as item in list
league[[i]] <- data
}
# bind rows of loop, add lagged values
league <- bind_rows(league)
league <- list()
for (i in 1:51) {
# get detailed data for users
data <- jsonlite::read_json(paste0("https://fantasy.premierleague.com/drf/leagues-classic-standings/268527?phase=1&lsPage=", i),
simplifyVector = TRUE)
# append dataframe as item in list
league[[i]] <- data$standings$results
}
league <- bind_rows(league)
View(league)
# create empty list to append gameweek-level data to
leagueDetailed <- list()
# loop through user ids
for (i in league$entry) {
# get detailed data for users
data <- userPerformance(user_id = i)
# append dataframe as item in list
leagueDetailed[[i]] <- data
}
listings <- read_csv("listings.csv.gz")
library(tidyverse)
library(fplR)
library(hrbrthemes)
library(ggalt)
library(forcats)
library(zoo)
require(tidytext)
require(stringr)
listings <- read_csv("listings.csv.gz")
reviews <- read_csv("reviews.csv.gz")
require(sf)
install.packages("sf")
install.packages("sf")
install.packages(c("bindrcpp", "clipr", "DBI", "dplyr", "evaluate", "foreign", "geofacet", "glue", "hexSticker", "quantmod", "survey", "tidytext", "XML"))
install.packages("sf")
install.packages("sf")
devtools::install_github('edzer/sfr')
install.packages("sf")
library(tidyverse)
library(hrbrthemes)
library(ggalt)
library(forcats)
require(tidytext)
require(stringr)
require(sf)
listings_detailed <- read_csv("listings.csv.gz")
reviews_detailed <- read_csv("reviews.csv.gz")
calendar <- read_csv("calendar.csv.gz")
library(data.table)
library(tidyverse)
library(hrbrthemes)
library(ggalt)
library(forcats)
require(tidytext)
require(stringr)
require(sf)
require(sparklyr)
sc <- spark_connect(master = "local")
listings_detailed <- fread("listings.csv.gz")
listings_detailed <- read_csv("listings.csv.gz")
reviews_detailed <- read_csv("reviews.csv.gz")
listings <- read_csv("listings.csv")
rm(listings)
reviews <- read_csv("reviews.csv")
rm(reviews)
sc <- spark_connect(master = "local")
listings <- read_csv("listings.csv.gz")
reviews <- read_csv("reviews.csv.gz")
calendar <- copy_to(sc, "calendar.csv.gz")
rm(sc)
neighbourhoods <- read_csv("neighbourhoods.csv")
library(tidyverse)
library(hrbrthemes)
library(ggalt)
library(forcats)
require(tidytext)
require(stringr)
require(sf)
listings <- read_csv("listings.csv.gz")
reviews <- read_csv("reviews.csv.gz")
neighbourhoods <- read_csv("neighbourhoods.csv")
neighbourhoods_geojson <- read_sf("neighbourhoods.geojson")
rm(neighbourhoods)
neighbourhoods <- read_sf("neighbourhoods.geojson")
rm(neighbourhoods_geojson)
sapply(reviews, function(x) sum(is.na(x)))
listings$price <- as.numeric(sub("\\$","", listings$price))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), as.numeric(sub("\\$","")))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), as.numeric(sub("\\$","", ...)))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), as.numeric(str_replace("\\$","")))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), str_replace("\\$",""))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), str_replace(., "\\$",""))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), str_replace(..., "\\$",""))
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), str_replace(, "\\$",""))
listings <- read_csv("listings.csv.gz")
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
require(quantmod)
unique(listings$last_scraped)
rate <- getFX("GBP/USD", from="2017-03-05", to="2016-03-04")
getFX("GBP/USD", from="2017-03-05", to="2016-03-04")
min(listings$last_scraped)
rate <- getFX("GBP/USD", from=min(listings$last_scraped), to=max(listings$last_scraped))
rm(rate)
GBPUSD
GBPUSD[, 1]
GBPUSD[2 , 1]
[2 , 2]
GBPUSD[2 , 2]
GBPUSD[2 , 1]
as.numeric(GBPUSD[2 , 1])
listings <- mutate_at(listings, c("price", "weekly_price", "monthly_price"), x*as.numeric(GBPUSD[2 , 1]))
listings <- mutate(listings,
price=price*as.numeric(GBPUSD[2 , 1]))
getFX("USD/GBP", from=min(listings$last_scraped), to=max(listings$last_scraped))
View(GBPUSD)
View(USDGBP)
rm(GBPUSD)
listings <- read_csv("listings.csv.gz")
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
listings <- mutate(listings,
price=price*as.numeric(USDGBP[2 , 1]),
weekly_price=weekly_price*as.numeric(USDGBP[2 , 1]),
monthly_price=monthly_price*as.numeric(USDGBP[2 , 1]))
listings <- read_csv("listings.csv.gz")
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
listings$security_deposit <- as.numeric(str_replace(listings$security_deposit, "\\$",""))
listings$extra_people <- as.numeric(str_replace(listings$extra_people, "\\$",""))
listings <- mutate(listings,
price=price*as.numeric(USDGBP[2 , 1]),
weekly_price=weekly_price*as.numeric(USDGBP[2 , 1]),
monthly_price=monthly_price*as.numeric(USDGBP[2 , 1]),
security_deposit=security_deposit*as.numeric(USDGBP[2 , 1]),
extra_people=extra_people*as.numeric(USDGBP[2 , 1]))
install.packages("tidycensus")
rm(USDGBP)
View(listings)
listings <- read_csv("listings.csv.gz")
#convert prices to numeric
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
listings$security_deposit <- as.numeric(str_replace(listings$security_deposit, "\\$",""))
listings$extra_people <- as.numeric(str_replace(listings$extra_people, "\\$",""))
#currency conversion
getFX("USD/GBP", from=min(listings$last_scraped), to=max(listings$last_scraped))
listings <- mutate(listings,
price=round(price*as.numeric(USDGBP[2 , 1])),
weekly_price=round(weekly_price*as.numeric(USDGBP[2 , 1])),
monthly_price=round(monthly_price*as.numeric(USDGBP[2 , 1])),
security_deposit=round(security_deposit*as.numeric(USDGBP[2 , 1])),
extra_people=round(extra_people*as.numeric(USDGBP[2 , 1])))
rm(USDGBP)
listings <- read_csv("listings.csv.gz")
#convert prices to numeric
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
listings$security_deposit <- as.numeric(str_replace(listings$security_deposit, "\\$",""))
listings$extra_people <- as.numeric(str_replace(listings$extra_people, "\\$",""))
listings$cleaning_fee <- as.numeric(str_replace(listings$cleaning_fee, "\\$",""))
#currency conversion
getFX("USD/GBP", from=min(listings$last_scraped), to=max(listings$last_scraped))
listings <- mutate(listings,
price=round(price*as.numeric(USDGBP[2 , 1])),
weekly_price=round(weekly_price*as.numeric(USDGBP[2 , 1])),
monthly_price=round(monthly_price*as.numeric(USDGBP[2 , 1])),
security_deposit=round(security_deposit*as.numeric(USDGBP[2 , 1])),
extra_people=round(extra_people*as.numeric(USDGBP[2 , 1])),
cleaning_fee=round(cleaning_fee*as.numeric(USDGBP[2 , 1])))
rm(USDGBP)
test <- readxl::read_excel("https://files.datapress.com/london/dataset/uk-house-price-index/2017-06-08T08:45:06.39/UK%20House%20price%20index-v2.xls")
library(readxl)
house_prices <- read_excel("UK House price index-v2.xls", sheet = "Average price")
View(house_prices)
knitr::opts_chunk$set(cache=TRUE, echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, out.width = '100%', dpi = 180, echo = FALSE)
library(tidyverse)
library(hrbrthemes)
library(ggalt)
library(forcats)
require(tidytext)
require(stringr)
require(sf)
require(quantmod)
library(readxl)
# read in airbnb data locally
listings <- read_csv("listings.csv.gz")
reviews <- read_csv("reviews.csv.gz")
neighbourhoods <- read_sf("neighbourhoods.geojson")
# read in house price data
house_prices <- read_excel("UK House price index-v2.xls", sheet = "Average price")
quantile(listings$price,
probs = seq(0, 1, 0.01),
na.rm = TRUE) #Median price around £90, upper quartile > 150
listings$price <- as.numeric(str_replace(listings$price, "\\$",""))
listings$weekly_price <- as.numeric(str_replace(listings$weekly_price, "\\$",""))
listings$monthly_price <- as.numeric(str_replace(listings$monthly_price, "\\$",""))
listings$security_deposit <- as.numeric(str_replace(listings$security_deposit, "\\$",""))
listings$extra_people <- as.numeric(str_replace(listings$extra_people, "\\$",""))
listings$cleaning_fee <- as.numeric(str_replace(listings$cleaning_fee, "\\$",""))
#currency conversion
getFX("USD/GBP", from=min(listings$last_scraped), to=max(listings$last_scraped))
listings <- mutate(listings,
price=round(price*as.numeric(USDGBP[2 , 1])),
weekly_price=round(weekly_price*as.numeric(USDGBP[2 , 1])),
monthly_price=round(monthly_price*as.numeric(USDGBP[2 , 1])),
security_deposit=round(security_deposit*as.numeric(USDGBP[2 , 1])),
extra_people=round(extra_people*as.numeric(USDGBP[2 , 1])),
cleaning_fee=round(cleaning_fee*as.numeric(USDGBP[2 , 1])))
rm(USDGBP)
quantile(listings$price,
probs = seq(0, 1, 0.01),
na.rm = TRUE) #Median price around £90, upper quartile > 150
View(house_prices)
listings <- mutate(listings, percentile=quantile(price, probs = seq(0, 1, 0.01),
na.rm = TRUE))
listings <- mutate(listings, percentile=cut(price, breaks = quantile(price, probs = seq(0, 1, 0.01),
na.rm = TRUE)))
listings <- mutate(listings, percentile=cut(price, breaks = quantile(price, probs = seq(0, 1, 0.01))))
listings <- mutate(listings, percentile=cut(price, breaks = quantile(price, probs = seq(0, 1, 0.01),
na.rm = TRUE)))
listings <- mutate(listings, percentile=ntile(price, 100))
listings <- mutate(listings, percentile=ntile(price, 100),
one_percent=ifelse(percentile==100, TRUE, FALSE))
listings_words <- listings %>%
select(id, description, price, price_uq, review_scores_accuracy, review_scores_rating) %>%
unnest_tokens(word, description) %>%
filter(!word %in% stop_words$word,
str_detect(word, "^[a-z']+$"))
listings_words <- listings %>%
select(id, description, price, percentile, one_percent, review_scores_accuracy, review_scores_rating) %>%
unnest_tokens(word, description) %>%
filter(!word %in% stop_words$word,
str_detect(word, "^[a-z']+$"))
listings_words %>%
group_by(word) %>%
summarise(count = n()) %>%
top_n(n = 20, wt = count) %>%
ggplot() +
geom_bar(mapping = aes(x=reorder(word, -count),
y=count),
stat="identity") +
coord_flip()
listings_words %>%
group_by(word) %>%
summarise(count = n()) %>%
top_n(n = 20, wt = count) %>%
ggplot() +
geom_bar(mapping = aes(x=reorder(word, -count),
y=count),
stat="identity") +
coord_flip()
leaflet(data = listings) %>% addProviderTiles("CartoDB.DarkMatter") %>%
addCircleMarkers(~longitude, ~latitude, radius = 0.2, fillOpacity = 0.5)
install.packages("leaflet")
library(leaflet)
leaflet(data = listings) %>% addProviderTiles("CartoDB.DarkMatter") %>%
addCircleMarkers(~longitude, ~latitude, radius = 0.2, fillOpacity = 0.5)
leaflet(data = listings) %>% addProviderTiles("CartoDB.DarkMatter") %>%
addCircleMarkers(~longitude, ~latitude, radius = 0.2, fillOpacity = 0.5)
ggplot(data = listings, aes(x=longitude, y=latitude)) +
geom_point()
ggplot(data = listings, aes(x=longitude, y=latitude)) +
geom_point(alpha=0.5)
ggplot(data = listings, aes(x=longitude, y=latitude)) +
geom_point(alpha=0.2)
ggplot(data = listings, aes(x=longitude, y=latitude)) +
geom_point(alpha=0.1)
ggplot(data = listings, aes(x=longitude, y=latitude)) +
geom_point(alpha=0.1) +
geom_polygon(data = neighbourhoods)
devtools::install_github("tidyverse/ggplot2")
shiny::runApp('Documents/Github/polMonitor')
setwd("~/Documents/Github/polMonitor")
# pkgs
library(shiny)
library(shinythemes)
library(tidyverse)
library(sf)
library(leaflet)
library(RColorBrewer)
library(viridis)
library(tigris)
library(tidycensus)
library(lubridate)
# LOAD ----------------------------------------------------------------
# load census data
censusData <- read_csv("censusData.csv")
#load state shapefile
states <- st_read("tl_2015_us_state")
state_names <- select(as.data.frame(states), STUSPS, NAME)
# load deaths data
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
left_join(state_names, by=c("Location of death (state)"="STUSPS"))
View(mpv_data)
runApp()
mpv_data$NAME <- as.factor(as.character(mpv_data$NAME))
runApp()
runApp()
runApp()
mean(mpv_data$lon)
mean(mpv_data$lon, na.rm=TRUE)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(mpv_data)
runApp()
runApp()
states <- st_read("tl_2015_us_state") %>%
state_names <- select(as.data.frame(states), STUSPS, NAME, geometry)
states <- st_read("tl_2015_us_state") %>%
state_names <- select(states, STUSPS, NAME, geometry)
states <- st_read("tl_2015_us_state")
state_names <- select(states, STUSPS, NAME, geometry)
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
right_join(states, by=c("Location of death (state)"="STUSPS"))
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
st_join(state_names, by=c("Location of death (state)"="STUSPS"))
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
st_as_sf()
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
st_as_sf(coords=c("lon", "lat"))
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE))
missing_geocode <- filter(mpv_data, is.na(lon) | is.na(lat))
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat"))
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat")) %>%
st_join(state_names)
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat")) %>%
st_join(state_names, join= st_contains)
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat"))
states <- st_read("tl_2015_us_state")
state_names <- select(states, STUSPS, NAME, geometry)
# load deaths data
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE))
# CLEAN ----------------------------------------------------------------
# df of missing geocodes
missing_geocode <- filter(mpv_data, is.na(lon) | is.na(lat))
# remove missing geocodes from original df
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat")) %>%
st_join(state_names)
View(state_names)
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))  %>%
st_as_sf(coords=c("lon", "lat"))
runApp()
runApp()
runApp()
# LOAD ----------------------------------------------------------------
# load census data
censusData <- read_csv("censusData.csv")
#load state shapefile
states <- st_read("tl_2015_us_state")
state_names <- select(as.data.frame(states), STUSPS, NAME)
# load deaths data
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
left_join(state_names, by=c("Location of death (state)"="STUSPS"))
runApp()
install.packages("DT")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
cleantable <- mpv_data %>%
select(Name=`Victim's name`, Age=`Victim's age`, Gender=`Victim's gender`, Race=`Victim's race`,
Photo=`URL of image of victim`, Date=`Date of injury resulting in death (month/day/year)`,
City=`Location of death (city)`, State=NAME, Zipcode=`Location of death (zip code)`,
`Agency responsible for death`, `Cause of death`)
View(cleantable)
runApp()
runApp()
runApp()
setwd("~/Documents/Github/polMonitor")
# pkgs
library(shiny)
library(shinythemes)
library(tidyverse)
library(sf)
library(leaflet)
library(RColorBrewer)
library(viridis)
library(tigris)
library(tidycensus)
library(lubridate)
# LOAD ----------------------------------------------------------------
# load census data
censusData <- read_csv("censusData.csv")
#load state shapefile
states <- st_read("tl_2015_us_state")
state_names <- select(as.data.frame(states), STUSPS, NAME)
# load deaths data
mpv_data <- read_csv("geocodedMPVDataset.csv") %>%
mutate(month=month(`Date of injury resulting in death (month/day/year)`, label=TRUE)) %>%
left_join(state_names, by=c("Location of death (state)"="STUSPS"))
# CLEAN ----------------------------------------------------------------
# df of missing geocodes
missing_geocode <- filter(mpv_data, is.na(lon) | is.na(lat))
# remove missing geocodes from original df
mpv_data <- filter(mpv_data, !is.na(lon) & !is.na(lat))
# factor vars
censusData$gender <- as.factor(censusData$gender)
censusData$age_band <- as.factor(censusData$age_band)
censusData$race <- as.factor(censusData$race)
mpv_data$`Victim's gender` <- as.factor(mpv_data$`Victim's gender`)
mpv_data$`Victim's age band` <- as.factor(mpv_data$`Victim's age band`)
mpv_data$`Victim's race` <- as.factor(mpv_data$`Victim's race`)
mpv_data$NAME <- as.factor(as.character(mpv_data$NAME))
# variables for data table
cleantable <- mpv_data %>%
select(Name=`Victim's name`, Age=`Victim's age`, Gender=`Victim's gender`, Race=`Victim's race`,
Photo=`URL of image of victim`, Date=`Date of injury resulting in death (month/day/year)`,
City=`Location of death (city)`, State=NAME, Zipcode=`Location of death (zip code)`,
`Agency responsible for death`, `Cause of death`)
runApp()
cleantable$Zipcode <- formatC(cleantable$Zipcode, width=5, format="d", flag="0")
row.names(cleantable) <- cleantable$Name
runApp()
runApp()
levels(cleantable$State)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
